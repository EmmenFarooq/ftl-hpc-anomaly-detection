{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6533f5",
   "metadata": {},
   "source": [
    "# Federated Transfer Learning for Anomaly Detection in HPC Systems\n",
    "This notebook simulates FTL using a dense autoencoder and TensorFlow Federated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow_federated scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e9361",
   "metadata": {},
   "source": [
    "## Simulate Data for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_data(n_samples=500, n_features=462, anomaly_ratio=0.03):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, n_features))\n",
    "    y = np.random.choice([0, 1], size=n_samples, p=[1-anomaly_ratio, anomaly_ratio])\n",
    "    return X, y\n",
    "\n",
    "client_data = [generate_node_data() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fae26e",
   "metadata": {},
   "source": [
    "## Define Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d53a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_dim),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(80, activation='relu'),\n",
    "        tf.keras.layers.Dense(60, activation='relu'),\n",
    "        tf.keras.layers.Dense(40, activation='relu'),\n",
    "        tf.keras.layers.Dense(20, activation='relu'),  # latent\n",
    "        tf.keras.layers.Dense(40, activation='relu'),\n",
    "        tf.keras.layers.Dense(60, activation='relu'),\n",
    "        tf.keras.layers.Dense(80, activation='relu'),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-6),\n",
    "                  loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e0240",
   "metadata": {},
   "source": [
    "## Preprocessing and Federated Learning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(data)\n",
    "\n",
    "def model_fn():\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model=create_autoencoder(input_dim=462),\n",
    "        input_spec=tf.TensorSpec([None, 462], tf.float32),\n",
    "        loss=tf.keras.losses.MeanSquaredError()\n",
    "    )\n",
    "\n",
    "def get_federated_data():\n",
    "    federated_data = []\n",
    "    for X, _ in client_data:\n",
    "        X_scaled = preprocess(X)\n",
    "        federated_data.append(tf.data.Dataset.from_tensor_slices(X_scaled).batch(10))\n",
    "    return federated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94258ba9",
   "metadata": {},
   "source": [
    "## Train Federated Model (FedAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d472c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_averaging = tff.learning.build_federated_averaging_process(model_fn)\n",
    "state = federated_averaging.initialize()\n",
    "\n",
    "for round_num in range(10):  # Example: 10 rounds\n",
    "    state, metrics = federated_averaging.next(state, get_federated_data())\n",
    "    print(f'Round {round_num+1}, Loss: {metrics.loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b3196",
   "metadata": {},
   "source": [
    "## Transfer Learning to Unseen Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen, y_unseen = generate_node_data()\n",
    "X_unseen_scaled = preprocess(X_unseen)\n",
    "\n",
    "global_model = create_autoencoder(input_dim=462)\n",
    "global_model.set_weights(state.model.trainable)\n",
    "\n",
    "for layer in global_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "global_model.compile(optimizer='RMSprop', loss='mse')\n",
    "global_model.fit(X_unseen_scaled, X_unseen_scaled, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b358f",
   "metadata": {},
   "source": [
    "## Evaluate on Unseen Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e499ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = global_model.predict(X_unseen_scaled)\n",
    "recon_error = np.mean((X_unseen_scaled - reconstructed)**2, axis=1)\n",
    "threshold = 0.5\n",
    "predictions = (recon_error > threshold).astype(int)\n",
    "\n",
    "print(\"F1-Score:\", f1_score(y_unseen, predictions))\n",
    "print(\"Precision:\", precision_score(y_unseen, predictions))\n",
    "print(\"Recall:\", recall_score(y_unseen, predictions))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}